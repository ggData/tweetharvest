{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `tweetharvest`: Example Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example notebook demonstrating how to establish a connection to a database of tweets collected using [`tweetharvest`](https://github.com/ggData/tweetharvest). It presupposes that all [the setup instructions](https://github.com/ggData/tweetharvest/blob/master/README.md) have been completed (see README file for that repository) and that MongoDB server is running as described there. We start by importing core packages the [PyMongo package](http://api.mongodb.org/python/current/index.html), the official package to access MongoDB databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we establish a link with the database. We know that the database created by `tweetharvester` is called `tweets_db` and within it is a collection of tweets that goes by the name of the project, in this example: `emotweets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient('localhost', 27017), u'tweets_db'), u'emotweets')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pymongo.MongoClient().tweets_db\n",
    "coll = db.emotweets\n",
    "coll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have an object, `coll`, that offers full access to the MongoDB API where we can analyse the data in the collected tweets. For instance, in our small example collection, we can count the number of tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1091"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can count the number of tweets that are geolocated with a field containing the latitude and longitude of the user when they sent the tweet. We construct a MongoDB query that looks for a non-empty field called `coordinates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {'coordinates': {'$ne': None}}\n",
    "coll.find(query).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or how many tweets had the hashtag `#happy` in them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {'hashtags': {'$in': ['happy']}}\n",
    "coll.find(query).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to perform these analyses there are a few things one needs to know:\n",
    "\n",
    "1. At the risk of stating the obvious: how to code in [Python](http://www.python.org) (there is also [an excellent tutorial](https://docs.python.org/2/tutorial/)). Please note that the current version of `tweetharvest` uses Python 2.7, and not Python 3.\n",
    "2. How to perform mongoDB queries, including aggregation, counting, grouping of subsets of data. There is a most effective short introduction ([The Little Book on MongoDB](http://openmymind.net/mongodb.pdf) by Karl Seguin), as well as [extremely rich documentation](http://docs.mongodb.org/manual/reference/) on the parent website.\n",
    "3. [How to use PyMongo](http://api.mongodb.org/python/current/) to interface with the MongoDB API.\n",
    "\n",
    "Apart from these skills, one needs to know how each status is stored in the database. Here is an easy way to look at the data structure of one tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'_id': 608980543552794624L,\n",
       " u'contributors': None,\n",
       " u'coordinates': None,\n",
       " u'created_at': datetime.datetime(2015, 6, 11, 12, 54, 10),\n",
       " u'entities': {u'hashtags': [{u'indices': [109, 113], u'text': u'sad'}],\n",
       "  u'symbols': [],\n",
       "  u'urls': [],\n",
       "  u'user_mentions': [{u'id': 330185970,\n",
       "    u'id_str': u'330185970',\n",
       "    u'indices': [0, 10],\n",
       "    u'name': u'Pause Pub',\n",
       "    u'screen_name': u'pause_pub'}]},\n",
       " u'favorite_count': 0,\n",
       " u'favorited': False,\n",
       " u'geo': None,\n",
       " u'hashtags': [u'sad'],\n",
       " u'id_str': u'608980543552794624',\n",
       " u'in_reply_to_screen_name': u'pause_pub',\n",
       " u'in_reply_to_status_id': 608977999069872128L,\n",
       " u'in_reply_to_status_id_str': u'608977999069872128',\n",
       " u'in_reply_to_user_id': 330185970,\n",
       " u'in_reply_to_user_id_str': u'330185970',\n",
       " u'is_quote_status': False,\n",
       " u'lang': u'fr',\n",
       " u'metadata': {u'iso_language_code': u'fr', u'result_type': u'recent'},\n",
       " u'place': None,\n",
       " u'retweet_count': 0,\n",
       " u'retweeted': False,\n",
       " u'source': u'<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " u'text': u\"@pause_pub ah mais en fait non... Ca ne va pas etre possible le vendredi :( laissons la place \\xe0 qqun d'autre #sad\",\n",
       " u'truncated': False,\n",
       " u'user': {u'contributors_enabled': False,\n",
       "  u'created_at': datetime.datetime(2012, 5, 2, 20, 11, 19),\n",
       "  u'default_profile': False,\n",
       "  u'default_profile_image': False,\n",
       "  u'description': u\"Bachelor\\xe9e Chef de Projet #publicit\\xe9 #marketing #communication \\xe0 l'@_E_S_P_ | \\xc9prise de #F1 #digital #photos | Content Manager @Socialy | Last @Cubeek3D\",\n",
       "  u'entities': {u'description': {u'urls': []}},\n",
       "  u'favourites_count': 1389,\n",
       "  u'follow_request_sent': None,\n",
       "  u'followers_count': 317,\n",
       "  u'following': None,\n",
       "  u'friends_count': 273,\n",
       "  u'geo_enabled': True,\n",
       "  u'id': 569469597,\n",
       "  u'id_str': u'569469597',\n",
       "  u'is_translation_enabled': False,\n",
       "  u'is_translator': False,\n",
       "  u'lang': u'fr',\n",
       "  u'listed_count': 68,\n",
       "  u'location': u'Paris, France',\n",
       "  u'name': u'Gwendoline Moortgat',\n",
       "  u'notifications': None,\n",
       "  u'profile_background_color': u'DBE9ED',\n",
       "  u'profile_background_image_url': u'http://abs.twimg.com/images/themes/theme17/bg.gif',\n",
       "  u'profile_background_image_url_https': u'https://abs.twimg.com/images/themes/theme17/bg.gif',\n",
       "  u'profile_background_tile': False,\n",
       "  u'profile_banner_url': u'https://pbs.twimg.com/profile_banners/569469597/1413568721',\n",
       "  u'profile_image_url': u'http://pbs.twimg.com/profile_images/470839037826441216/7N7THT3E_normal.jpeg',\n",
       "  u'profile_image_url_https': u'https://pbs.twimg.com/profile_images/470839037826441216/7N7THT3E_normal.jpeg',\n",
       "  u'profile_link_color': u'CC3366',\n",
       "  u'profile_sidebar_border_color': u'DBE9ED',\n",
       "  u'profile_sidebar_fill_color': u'E6F6F9',\n",
       "  u'profile_text_color': u'333333',\n",
       "  u'profile_use_background_image': True,\n",
       "  u'protected': False,\n",
       "  u'screen_name': u'GMrtgt',\n",
       "  u'statuses_count': 3129,\n",
       "  u'time_zone': u'Paris',\n",
       "  u'url': None,\n",
       "  u'utc_offset': 7200,\n",
       "  u'verified': False}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This JSON data structure is [documented on the Twitter API website](https://dev.twitter.com/overview/api/tweets) where each field is described in detail. It is recommended that this description is studied in order to understand how to construct valid queries.\n",
    "\n",
    "`tweetharvest` is faithful to the core structure of the tweets as described in that documentation, but with minor differences created for convenience:\n",
    "\n",
    "1. All date fields are stored as MongoDB `Date` objects and returned as Python `datetime` objects. This makes it easier to work on date ranges, sort by date, and do other date and time related manipulation.\n",
    "2. A `hashtags` field is created for convenience. This contains a simple array of all the hashtags contained in a particular tweet and can be queried directly instead of looking for tags inside a dictionary, inside a list of other entities. It is included for ease of querying but may be ignored if one prefers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook establishes how you can connect to the database of tweets that you have harvested and how you can use the power of Python and MongoDB to access and analyse your collections. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
